{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Akshata Bheemasamudra Mallikarjunappa\n",
        "\n",
        "Student ID: 23164204\n",
        "\n",
        "**Improvements:**\n",
        "\n",
        "1. The 1st post had formulas mentioned for Precision and F1 only, this file includes the formula for recall as well.\n",
        "2. After looking into Enda's file, I learnt we can output the sentiment of the sentence using polarity and that the positive and negative words dataframe used in the previous activity was not needed. Hence, incorporated the same in this file.\n",
        "3. Joe's file helped me incorporate the conditional probability for each word."
      ],
      "metadata": {
        "id": "-URuc8AvlhRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task1:**"
      ],
      "metadata": {
        "id": "45icha_Emjv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###a.\n",
        "\n",
        "$$Micro-Averaged \\ Precision\n",
        "= \\frac{Class\\ 1\\ TP + Class\\ 2 \\ TP}{(TP \\ of \\ class \\ 1 \\  and \\ 2)+((FP \\ of \\ class \\ 1 \\ and \\ 2)}\n",
        "= \\frac{800+70}{(800+70)+(200+30)} = 0.7909$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$Micro-Averaged \\ Recall\n",
        "= \\frac{Class\\ 1\\ TP + Class\\ 2 \\ TP}{(TP\\ of \\ class \\ 1 \\ and \\  2)+(FN\\ of \\ class \\ 1 \\ and \\ 2)}\n",
        "= \\frac{800+70}{(800+70)+(200+30)} = 0.7909$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$Micro-Averaged \\ F1\n",
        "= \\frac{2 \\times Micro-Averaged \\ Precision \\times Micro-Averaged \\ Recall}{(Micro-Averaged \\ Precision + Micro-Averaged \\ Recall}\n",
        "= \\frac{2 \\times 0.7909 \\times 0.7909}{(0.7907+0.7909)} = 0.7908$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "###b.\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$Macro-Averaged \\ Precision\n",
        "= \\frac{\\frac{TP \\ of \\ class \\ 1}{( TP + FP) \\ of \\ class \\ 1} + \\frac{TP \\ of \\ class \\ 2}{( TP + FP) \\ of \\ class\\ 2}} {2}\n",
        "= \\frac{\\frac{800}{(800+200)} + \\frac{70}{(70+30)}}{2} = \\frac {(0.8+0.7)}{2} = 0.75$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$Macro-Averaged \\ Recall = \\frac{\\frac{TP \\ of \\ class \\ 1}{( TP + FN) \\ of \\ class \\ 1} + \\frac{TP \\ of \\ class \\ 2}{( TP + FN) \\ of \\ class\\ 2}} {2}\n",
        "= \\frac{\\frac{800}{(800+200)} + \\frac{70}{(70+30)}}{2} = \\frac {(0.8+0.7)}{2} = 0.75$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$Macro-Averaged \\ F1 = \\frac{2 \\times Macro-Averaged \\ Precision \\times Macro-Avergaed \\ Recall}{(Macro-Averaged \\ Precision + Macro-Avergaed \\ Recall} =  \\frac{2 \\times 0.75 \\times 0.75}{(0.75+0.75)} \\ = 0.75$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "###c.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Micro-Averaged F1 is used to calculate the accuracy using the precision and recall of the total classes, it combines the parameters of both the classes and averages the sum. Whereas Macro-Averaged F1 is calculated using precision and recall separately for each class, it considers parameters of both the classes separately and then averages it.\n"
      ],
      "metadata": {
        "id": "jir0dEzUpCaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task3**"
      ],
      "metadata": {
        "id": "cR6PXyuDtM6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from textblob import TextBlob\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "X_rSr9OGmh_O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentimentAnalyzer(string):\n",
        "\n",
        "  print('string =', string , '\\n')\n",
        "\n",
        "  Sentence = TextBlob(string)\n",
        "  print(Sentence.sentiment)\n",
        "\n",
        "  if Sentence.sentiment.polarity > 0.1:\n",
        "   print(\"Positive statement\")\n",
        "  elif Sentence.sentiment.polarity < 0.1:\n",
        "   print(\"Negative statement\")\n",
        "  else:\n",
        "   print(\"Neutral statement\")\n",
        "\n",
        "  print('Subjectivity:', Sentence.subjectivity)\n",
        "  print('--------------------------------------------------------')"
      ],
      "metadata": {
        "id": "LHaCFyw7tTQ7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentAnalyzer(\"NLP is cool\")\n",
        "sentimentAnalyzer(\"NLP is cool and useful\")\n",
        "sentimentAnalyzer(\"NLP is hard\")\n",
        "sentimentAnalyzer(\"NLP is hard and useless\")\n",
        "sentimentAnalyzer(\"NLP stands for Natural Language Processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzOdAUN_thOW",
        "outputId": "82b64600-a1e9-4249-dfa7-ebe07515cb28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "string = NLP is cool \n",
            "\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "Positive statement\n",
            "Subjectivity: 0.65\n",
            "--------------------------------------------------------\n",
            "string = NLP is cool and useful \n",
            "\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "Positive statement\n",
            "Subjectivity: 0.325\n",
            "--------------------------------------------------------\n",
            "string = NLP is hard \n",
            "\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "Negative statement\n",
            "Subjectivity: 0.5416666666666666\n",
            "--------------------------------------------------------\n",
            "string = NLP is hard and useless \n",
            "\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "Negative statement\n",
            "Subjectivity: 0.37083333333333335\n",
            "--------------------------------------------------------\n",
            "string = NLP stands for Natural Language Processing \n",
            "\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Neutral statement\n",
            "Subjectivity: 0.4\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task2**"
      ],
      "metadata": {
        "id": "67RA-ozBvgbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def naiveBayesClassifier(trainingSet,testSet):\n",
        "\n",
        " megaDocNeg, megaDocPos = [], []\n",
        " probNeg, probPos = 0, 0\n",
        " Neg_BOW, Pos_BOW = {}, {}\n",
        " V = {}\n",
        " ClassCountNeg, ClassCountPos = 0, 0\n",
        " n = len(trainingSet)\n",
        "\n",
        " for i in trainingSet:\n",
        "  words,id  = i[0].split(), i[1]\n",
        "\n",
        "  if id == '-':\n",
        "   ClassCountNeg += len(words)\n",
        "   probNeg += 1\n",
        "   for j in words:\n",
        "    if j not in megaDocNeg:\n",
        "     megaDocNeg.append(j)\n",
        "    if j in Neg_BOW:\n",
        "     Neg_BOW[j] += 1\n",
        "    else:\n",
        "     Neg_BOW[j] = 1\n",
        "\n",
        "  elif id == '+':\n",
        "   ClassCountPos += len(words)\n",
        "   probPos += 1\n",
        "   for j in words:\n",
        "    if j not in megaDocPos:\n",
        "     megaDocPos.append(j)\n",
        "    if j in Pos_BOW:\n",
        "     Pos_BOW[j] += 1\n",
        "    else:\n",
        "     Pos_BOW[j] = 1\n",
        "\n",
        "  else:\n",
        "    print('Error')\n",
        "\n",
        " V = Counter(Neg_BOW) + Counter(Pos_BOW)\n",
        "\n",
        " print(f'megaDocNeg= {megaDocNeg}')\n",
        " print(f'megaDocPos= {megaDocPos} \\n')\n",
        " print(f'probNeg = {str(probNeg/n)}  probPos = {str(probPos/n)}\\n')\n",
        " print(f'Neg_BOW= {Neg_BOW}')\n",
        " print(f'Pos_BOW= {Pos_BOW}\\n')\n",
        " print(f'V = {V}')\n",
        " print(f'|V|= {len(V)}')\n",
        "\n",
        "\n",
        " for k in testSet:\n",
        "  docProbNeg, docProbPos = probNeg, probPos\n",
        "\n",
        "  words = k[0].split()\n",
        "  print('------------------------------')\n",
        "  print(f'Test document = {str(k)} \\n')\n",
        "\n",
        "  for word in words:\n",
        "    wordConditionalProbNeg, wordConditionalProbPos = 0, 0\n",
        "\n",
        "\n",
        "    if word in Neg_BOW:\n",
        "      wordConditionalProbNeg = (Neg_BOW[word] + 1) / (ClassCountNeg + len(V))\n",
        "      docProbNeg *= wordConditionalProbNeg\n",
        "\n",
        "    if word in Pos_BOW:\n",
        "      wordConditionalProbPos = (Pos_BOW[word] + 1) / (ClassCountPos + len(V))\n",
        "      docProbPos *= wordConditionalProbPos\n",
        "\n",
        "    print(f'word =  {str(word)}    wordConditionalProbNeg =  {str(wordConditionalProbNeg)}    wordConditionalProbPos =   {str(wordConditionalProbPos)} \\n')\n",
        "\n",
        "  print(f'docProbNeg - = {str(docProbNeg)}   docProbPos  =  {str(docProbPos)}')\n",
        "\n",
        "  if docProbNeg < docProbPos:\n",
        "    print('Inferred class = +')\n",
        "\n",
        "  elif docProbNeg > docProbPos:\n",
        "    print('Inferred class = -')\n",
        "\n",
        "  else:\n",
        "    print('Inferred class = Belongs to both classes')"
      ],
      "metadata": {
        "id": "cFJ1AQQRvWU6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n",
        "testSet = [('predictable with no fun','?')]\n",
        "naiveBayesClassifier(trainingSet,testSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJSzwGIX6TH4",
        "outputId": "a7f3c802-f0be-48d2-9078-593fa6f56765"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "megaDocNeg= ['just', 'plain', 'boring', 'entirely', 'predictable', 'and', 'lacks', 'energy', 'no', 'surprises', 'very', 'few', 'laughs']\n",
            "megaDocPos= ['very', 'powerful', 'the', 'most', 'fun', 'film', 'of', 'summer'] \n",
            "\n",
            "probNeg = 0.6  probPos = 0.4\n",
            "\n",
            "Neg_BOW= {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n",
            "Pos_BOW= {'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "\n",
            "V = Counter({'and': 2, 'very': 2, 'the': 2, 'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'few': 1, 'laughs': 1, 'powerful': 1, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1})\n",
            "|V|= 20\n",
            "------------------------------\n",
            "Test document = ('predictable with no fun', '?') \n",
            "\n",
            "word =  predictable    wordConditionalProbNeg =  0.058823529411764705    wordConditionalProbPos =   0 \n",
            "\n",
            "word =  with    wordConditionalProbNeg =  0    wordConditionalProbPos =   0 \n",
            "\n",
            "word =  no    wordConditionalProbNeg =  0.058823529411764705    wordConditionalProbPos =   0 \n",
            "\n",
            "word =  fun    wordConditionalProbNeg =  0    wordConditionalProbPos =   0.06896551724137931 \n",
            "\n",
            "docProbNeg - = 0.010380622837370242   docProbPos  =  0.13793103448275862\n",
            "Inferred class = +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNs4JNGoM83A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}